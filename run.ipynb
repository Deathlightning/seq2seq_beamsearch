{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from src.train_method import train,evaluate\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import spacy\n",
    "from src.beam import beam_search_decoding, batch_beam_search_decoding\n",
    "from src.model import EncoderRNN, DecoderRNN, Attention, AttnDecoderRNN, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils {{{\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def init_weights(m):\n",
    "    for _, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def print_n_best(decoded_seq, itos):\n",
    "    for rank, seq in enumerate(decoded_seq):\n",
    "        print(f'Out: Rank-{rank+1}: {\" \".join([itos[idx] for idx in seq])}')\n",
    "# }}}\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SOS_token = '<SOS>'\n",
    "EOS_token = '<EOS>'\n",
    "config_dict={'batch_size': 512, 'n_epochs': 100, \n",
    "                 'enc_embd_size': 256, 'dec_embd_size': 256, \n",
    "                 'enc_h_size': 512, 'dec_h_size': 512, \n",
    "                 'beam_width': 10, 'n_best': 5, \n",
    "                 'max_dec_steps': 1000, \"load_pkl\":False,\n",
    "                 'model_name': 's2s', 'model_path': './s2s-vanilla.pt', \n",
    "                 'skip_train': False, 'attention': False}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "Unique tokens in source (de) vocabulary: 7853\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize=tokenize_de,\n",
    "                init_token=SOS_token,\n",
    "                eos_token=EOS_token,\n",
    "                lower=True)\n",
    "TRG = Field(tokenize=tokenize_en,\n",
    "            init_token=SOS_token,\n",
    "            eos_token=EOS_token,\n",
    "            lower=True)\n",
    "train_data, valid_data, test_data = Multi30k.splits(root=r'./',exts=('.de', '.en'), fields=(SRC, TRG))\n",
    "print(f'Number of training examples: {len(train_data.examples)}')\n",
    "print(f'Number of validation examples: {len(valid_data.examples)}')\n",
    "print(f'Number of testing examples: {len(test_data.examples)}')\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "print(f'Unique tokens in source (de) vocabulary: {len(SRC.vocab)}')\n",
    "print(f'Unique tokens in target (en) vocabulary: {len(TRG.vocab)}')\n",
    "\n",
    "train_itr, valid_itr, test_itr =\\\n",
    "        BucketIterator.splits(\n",
    "            (train_data, valid_data, test_data),\n",
    "            batch_size=config_dict[\"batch_size\"],\n",
    "            device=DEVICE)\n",
    "enc_v_size = len(SRC.vocab)\n",
    "dec_v_size = len(TRG.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(config_dict[\"enc_embd_size\"], config_dict[\"enc_h_size\"], config_dict.get(\"dec_h_size\"), enc_v_size)\n",
    "if config_dict[\"attention\"]:\n",
    "    attn = Attention(config_dict[\"enc_h_size\"], config_dict[\"dec_h_size\"])\n",
    "    decoder = AttnDecoderRNN(config_dict[\"dec_embd_size\"], config_dict[\"enc_h_size\"], config_dict[\"dec_h_size\"], dec_v_size, attn)\n",
    "else:\n",
    "    decoder = DecoderRNN(config_dict[\"dec_embd_size\"], config_dict[\"dec_h_size\"], dec_v_size)\n",
    "model = Seq2Seq(encoder, decoder,DEVICE).to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数，优化器，预训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "if config_dict[\"load_pkl\"] and config_dict[\"model_path\"] != '':\n",
    "    model.load_state_dict(torch.load(config_dict[\"model_path\"]))\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = MultiStepLR(optimizer, milestones=[0,100], gamma=0.1)\n",
    "loss_fn = nn.NLLLoss(ignore_index=TRG_PAD_IDX)\n",
    "log_softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/experiment_1\")\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(config_dict[\"n_epochs\"]):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_itr, optimizer,loss_fn,log_softmax)\n",
    "    valid_loss = evaluate(model, valid_itr, loss_fn,log_softmax)\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_time = time.time()-start_time\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        attn_type = 'attn' if config_dict[\"attention\"] else 'vanilla'\n",
    "        model_path = f'{config_dict[\"model_path\"]}'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    writer.add_scalar('train loss', train_loss,epoch+1)\n",
    "    writer.add_scalar('val loss', valid_loss,epoch+1)\n",
    "    writer.add_hparams(config_dict,{\n",
    "    \"train_loss\":train_loss,\n",
    "        \"val_loss\":valid_loss\n",
    "    },run_name=\"experiment_1\")\n",
    "    writer.add_scalar(\"epoch_time\",epoch_time,epoch+1)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    TRG_SOS_IDX = TRG.vocab.stoi[TRG.init_token]\n",
    "    TRG_EOS_IDX = TRG.vocab.stoi[TRG.eos_token]\n",
    "    for _, batch in enumerate(test_itr):\n",
    "        src = batch.src # (T, bs)\n",
    "        trg = batch.trg # (T, bs)\n",
    "        print(f'In: {\" \".join(SRC.vocab.itos[idx] for idx in src[:, 0])}')\n",
    "\n",
    "        enc_outs, h = model.encoder(src) # (T, bs, H), (bs, H)\n",
    "        # decoded_seqs: (bs, T)\n",
    "        start_time = time.time()\n",
    "        decoded_seqs = beam_search_decoding(decoder=model.decoder,\n",
    "                                            enc_outs=enc_outs,\n",
    "                                            enc_last_h=h,\n",
    "                                            beam_width=config_dict[\"beam_width\"],\n",
    "                                            n_best=config_dict[\"n_best\"],\n",
    "                                            sos_token=TRG_SOS_IDX,\n",
    "                                            eos_token=TRG_EOS_IDX,\n",
    "                                            max_dec_steps=config_dict[\"max_dec_steps\"],\n",
    "                                            device=DEVICE)\n",
    "        end_time = time.time()\n",
    "        print(f'for loop beam search time: {end_time-start_time:.3f}')\n",
    "        print_n_best(decoded_seqs[0], TRG.vocab.itos)\n",
    "\n",
    "        start_time = time.time()\n",
    "        decoded_seqs = batch_beam_search_decoding(decoder=model.decoder,\n",
    "                                                    enc_outs=enc_outs,\n",
    "                                                    enc_last_h=h,\n",
    "                                                    beam_width=config_dict[\"beam_width\"],\n",
    "                                                    n_best=config_dict[\"n_best\"],\n",
    "                                                    sos_token=TRG_SOS_IDX,\n",
    "                                                    eos_token=TRG_EOS_IDX,\n",
    "                                                    max_dec_steps=config_dict[\"max_dec_steps\"],\n",
    "                                                    device=DEVICE)\n",
    "        end_time = time.time()\n",
    "        print(f'Batch beam search time: {end_time-start_time:.3f}')\n",
    "        print_n_best(decoded_seqs[0], TRG.vocab.itos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
